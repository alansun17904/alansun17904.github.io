<!DOCTYPE html>
<html>
   <head>
      <meta charset="utf-8" />
      <meta name="viewport" content="width=device-width, initial-scale=1" />
      <title>Alan Sun</title>
      <link rel="stylesheet" href="styles.css">
      <!-- <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml.js"></script> -->
   </head>
   <body>
      <header>
         <img src="alan.jpeg" alt="Alan">
         <h1>Alan Sun</h1>
         <aside><b><a href="https://scholar.google.com/citations?user=QRJoXDQAAAAJ">Google Scholar</a>&nbsp;&nbsp;&nbsp;<a href="cv.pdf">CV</a></b></aside>
      </header>
      <p>I’m a second-year MSCS student at <i>Carnegie Mellon University</i>. I’m grateful to be supported by a <a href="https://www.nsfgrfp.org/">NSF Graduate Research Fellowship</a>.</p>
      <p>Before CMU, I was a visiting scholar at the <i>Max-Planck Institute for Software Systems</i> advised by <a href="https://mtoneva.com/">Mariya Toneva</a>. I earned my undergraduate degree in Computer Science and Mathematics at <i>Dartmouth College</i> with high honors. At Dartmouth, I did research with <a href="https://www.cs.dartmouth.edu/~soroush/">Soroush Vosoughi</a> where I created a formal framework to characterize the robustness of language models.</p>
      <h2>Research</h2>
      <p>
      I'm broadly interested in improving the reliability of language models. My work has approached this through three axes: (a) <u>evaluation</u>: how can we develop practical, principled measures of performance? (b) <u>attribution</u>: how do models encode and use structural patterns downstream? (c) <u>intervention</u>: how do we distill actionable insight from attributions for model improvement and control?
        </p>
        <p>Most recently, I've become interested in (1) understanding how/when language models acquire foundational, atomic skills during pre-training and how those acquisition schedules affect its ability to acquire capabilities downstream; (2) diffusion language models as a way to achieve human-like language generation and understanding.</p>
      <h2>Publications</h2>
      <p><i>(Ordered chronologically)</i></p>
      <ul>
          <li><i><a href="https://openreview.net/forum?id=9lycwRxAOI">Provably Tracking Equivalent Mechanistic Interpretations Across Neural Networks</a></i>.<br><b>Alan Sun</b>, Mariya Toneva.<br>ICLR (2026)</li>
          <li><i><a href="https://aclanthology.org/2025.acl-long.442/">Circuit Stability Characterizes Language Model Generalization</a></i>.<br><b>Alan Sun</b>.<br>ACL (2025)</li>
          <li><i><a href="https://arxiv.org/pdf/2412.07386">Algorithmic Phase Transitions in Language Models: A Mechanistic Case Study of Arithmetic</a></i>.<br><b>Alan Sun</b>, Ethan Sun, Warren Shepard.<br>2nd Workshop on Attributing Model Behavior at Scale @ NeurIPS (2024)</li>
          <li><i><a href="https://arxiv.org/abs/2411.01644">Achieving Domain-Independent Certified Robustness via Knowledge Continuity</a></i>.<br><b>Alan Sun</b>, Chiyu Ma, Kenneth Ge, Soroush Vosoughi.<br>NeurIPS (2024)</li>
          <li><i><a href="https://arxiv.org/abs/2411.00345?">On the Exploration of LM-Based Soft Modular Robot Design</a></i>.<br>Weicheng Ma, Luyang Zhao, Chun-Yi She, Yitao Jiang, <b>Alan Sun</b>, Bo Zhu, Devin Balkcom, Soroush Vosoughi.</li>
          <li><i><a href="https://aclanthology.org/2023.emnlp-main.697/">Deciphering Stereotypes in Pre-Trained Language Models</a></i>.<br>Weicheng Ma, Henry Scheible, Brian Wang, Goutham Veeramachaneni, Pratim Chowdhary, <b>Alan Sun</b>, Andrew Koulogeorge, Lili Wang, Diyi Yang, Soroush Vosoughi.<br>EMNLP (2023)</li>
          <li><i><a href="https://ieeexplore.ieee.org/document/9378287">ThanosNet: A Novel Trash Classification Method Using Metadata</a></i>.<br><b>Alan Sun</b>, Harry Xiao.<br>IEEE Big Data (2020)</li>
      </ul>
   </body>
</html>
